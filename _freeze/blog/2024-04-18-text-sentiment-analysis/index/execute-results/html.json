{
  "hash": "3cdf6a868f595e0ea5e3ccef4205d142",
  "result": {
    "markdown": "---\ntitle: \"Analyzing Text Sentiment from Online Articles Involving the Phrase 'water'\"\nauthor:\n  - name: Fletcher McConnell\n    url: https://fletcher-m.github.io/\n   # orcid:\n    affiliation: MEDS\n    affiliation-url: https://bren.ucsb.edu/masters-programs/master-environmental-data-science/academics-meds\n # - name: other person\ndate: 03-09-2024\ncategories: [sentiment analysis, MEDS, text analysis]\nbibliography: references.bib\ncitation:\n  url: https://fletcher-m.github.io/blog/2024-03-09-shark-aggression-analysis/\nimage: text_sentiment.png\neval: FALSE\n---\n\n\n# What is Text Sentiment Analysis?\n\nText sentiment analysis is an increasingly popular field that involves evaluating text data to identify and categorize sentiments such as positive, negative, or neutral. This technique utilizes a lexicon, which assigns sentiment values to words, to assess the overall sentiment of a given text. This method can also be used to identify popular \"topics\" within a set of text, by grouping words that commonly occur together. For example, a model may identify a group of words like \"amazon, deforestation, tree, burning, impact, biodiversity\" because these words have a high probability of occurring together. Text sentiment analysis has a variety of practical applications, one of which was illustrated by Nike's use of this method to monitor public opinion on social media following its sponsorship of NFL quarterback Colin Kaepernick.  \n\n# What I did for This Project\n\nFor this project, I used a relatively basic text analysis approach, where I downloaded 100 articles from the UCSB Library website, that had relation to the word \"water\". I then analyzed the overall sentiment of these articles, as well as a breakdown of the most common words within each sentiment category. I'll take you through the process below. \n\nThese were the packages that I used for this project and how I set up the directory to source the files from: \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# load libraries\nlibrary(LexisNexisTools)\nlibrary(dplyr)\nlibrary(readr)\nlibrary(stringr)\nlibrary(here)\nlibrary(tidytext)\nlibrary(tidyr)\nlibrary(ggplot2)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# set directory where the .docx files are located\nsetwd(here(\"~/Documents/EDS231/week2/Lab2/Data/library_articles_water\")) \npost_files <- list.files(pattern = \".docx\", path = getwd(),\n                      full.names = TRUE, recursive = TRUE, ignore.case = TRUE)\n```\n:::\n\n\nThis next step is t read in all of the .docx files and parcel out each of the components of those files. The three parts are the headline of the article, the article ID, and the text within each of those articles. This is necessary to perform analysis on these components later on.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# read in articles --> I chose articles involving \"water\"\ndat <- lnt_read(post_files)\n\n# separate components of each article\nmeta_df <- dat@meta\narticles_df <- dat@articles\nparagraphs_df <- dat@paragraphs\n\ndat2 <- tibble(Date = meta_df$Date, Headline = meta_df$Headline, id = articles_df$ID, text = articles_df$Article) |> \n  distinct(Headline, .keep_all = TRUE) # remove duplicate articles\n```\n:::\n\n\nThere are two different sentiment lexicons that I used for this analysis. The first, which I loaded below, is the bing sentiment lexicon. This is a binary classification system, where it assigns either a \"positive\" or a \"negative\" sentiment to each word. \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# load the bing sentiment lexicon from tidytext\nbing_sent <- get_sentiments(\"bing\")\n```\n:::\n\n\nDuring this next step, each of the articles is broken down into individual words (\"tokens\"). Then, the bing sentiment values are attached to each of those words. For more accurate results, stop-words are taken out of the word list. These are filler words (for, and, the etc.) that don't contribute to the analysis. \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# break down each article body into individual words\ntext_words <- dat2 |> unnest_tokens(output = word, input = text, token = 'words') |> \n filter(!grepl(\"\\\\.com$\", word)) # remove all words ending in \".com\" from list\n\n# add in sentiment associations with the words\nsent_words <- text_words |>\n  anti_join(stop_words, by = 'word') |> # take out stop words\n  inner_join(bing_sent, by = 'word') |> # add in sentiment associations\n  mutate(sent_num = case_when(sentiment == 'negative' ~ -1,\n                              sentiment == 'positive'~ 1))\nsent_words\n```\n:::\n\n\nHere is an example of what the output looks like:\n\n![](bing_words.png)\n\nThis next step uses the values assigned to each word above to calculate the average sentiment value over all of the articles.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nsent_article <- sent_words |> \n  group_by(Headline) |> \n  count(id, sentiment) |>  \n  pivot_wider(names_from = sentiment, values_from = n) |> \n  mutate(polarity = positive-negative)\n  \n# Calculate mean sentiment across all articles\nmean(sent_article$polarity, na.rm = TRUE)\n```\n:::\n\n\n It ended up calculating a value of -0.146. This means that, overall, the articles had a slightly negative sentiment. Here is a plot showing the breakdown of each of the articles and the number of positive and negative words in each. You can get a good idea of the general sentiment with this visual.\n \n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# plot sentiment breakdown for each article\nggplot(sent_article, aes(x = id)) +\n  theme_classic() +\n  geom_col(aes(y = positive, fill = \"Positive\"), stat = 'identity') +\n  geom_col(aes(y = negative, fill = \"Negative\"), stat = 'identity') +\n  labs(title = \"Sentiment Analysis: 'Water'\", x = 'Article ID', y = 'Count of Positive / Negative Words') +\n  scale_fill_manual(values = c(\"Positive\" = 'slateblue', \"Negative\" = 'red4'), name = \"Sentiment\") +\n  scale_x_continuous(expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  theme(plot.title = element_text(hjust = 0.5))\n```\n:::\n\n \n![](blue_red_plot.png)\n \nThis next section is where I use the second of the sentiment lexicons, that I mentioned earler. The \"nrc\" lexicon is a bit more complex than the \"bing\" lexicon. In addition to \"positive\" and \"negative\", it also includes \"anger\", \"fear\", \"anticipation\", \"trust\", \"surprise\", \"sadness\", \"joy\", and \"disgust\". This allows you to get a higher resolution picture of the sentiment breakdown across the articles. Below is the code a sample of the output for attaching this lexicon to the article words. \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# load nrc sentiment lexicon\nnrc_sent <- get_sentiments('nrc')\n\n# remove stop words and join nrc sentiments to article word list\nnrc_word_counts <- text_words |> \n  anti_join(stop_words, by = 'word') |> \n  inner_join(nrc_sent) |> \n  count(word, sentiment, sort = TRUE) |> \n  filter(word != \"soil\") # remove \"soil\" because of misleading classification in \"disgust\" category\n\n  \nnrc_word_counts\n```\n:::\n\n\n![](nrc_words.png)\n\nTo better visualize this, I made a plot that has each of the nrc sentiments that are listed above and the corresponding 5 most prevalent categorized words in each.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nnrc_word_counts |>  \n  group_by(sentiment) |> \n  slice_max(n, n = 5) |> \n  ungroup() |> \n  mutate(word = reorder(word, n)) |> \n  ggplot(aes(n, word, fill = sentiment)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~sentiment, scales = \"free_y\") +\n  labs(title = \"Top Words in Each NRC Emotion Category\",\n    x = \"Contribution to Sentiment\", y = NULL) +\n  theme(plot.title = element_text(hjust = 0.5))\n```\n:::\n\n\n![](nrc_plot.png)\n\nAs you can see, some sentiments are a bit more common among the articles, like \"positive\" and \"trust\". The overall average sentiment was computed using the bing sentiment, so that may explain why that ended up being a slightly negative value, instead of an assumed positive value from looking at this plot. \n\nThis last plot breaks down each sentiment category as a percentage of the total sentiment words. I grouped the articles by date, so you can get a visual of how proportions change over time. \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# join \"Date\" column onto nrc_word_counts data frame\nnrc_word_counts2 <- nrc_word_counts %>%\n  left_join(text_words |>  select(word, Date), by = \"word\")\n\n# calculate total number of emotion words for each day\ntotal_emotion_words_per_day <- nrc_word_counts2 |> \n  group_by(Date) |>   \n  summarize(total_emotion_words = sum(n))\n\n# calculate count of each emotion type per day\nemotion_type_count_per_day <- nrc_word_counts2 |> \n  group_by(Date, sentiment) |> \n  summarize(emotion_type_count = sum(n))\n\n# calculate percentage of total emotion words for each emotion type per day\nemotion_type_percentage_per_day <- emotion_type_count_per_day |> \n  inner_join(total_emotion_words_per_day, by = \"Date\") |> \n  mutate(percentage = (emotion_type_count / total_emotion_words) * 100)\n\n# plot percentage total emotion words of each emotion type over time \nggplot(emotion_type_percentage_per_day, aes(x = Date, y = percentage, color = sentiment)) +\n  geom_line() +\n  scale_color_viridis_d() +\n  scale_x_date(date_breaks = \"1 day\", date_labels = \"%Y-%m-%d\") +\n  labs(title = \"Percentages of NRC Emotion Words Over Time\",\n       x = \"Date\",\n       y = \"Percentage of Total Emotion Words\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank())\n```\n:::\n\n\n![](last_plot.png)\n\n# Takeaways\n\nThis was a relatively simple analysis, but had some really interesting insights. It seems like, for the articles involving water that I chose, the general sentiment is more positive than negative (ignoring the bing-calculated average). This process definitely has quite a bit of room for error. One example is that, originally, the nrc lexicon had put the term \"soil\" as one of the top 5 contributors to the \"disgust\" category. This was likely due to the fact that \"soil\" had more than one meaning (e.g. soil yourself or soil that plants grow in). I ended up removing that term because, in this context, that categorization did not make sense. Context is always important to pay attention to as well as different meanings and usages of words. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}